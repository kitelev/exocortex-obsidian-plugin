name: All Tests - Comprehensive Test Suite

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  workflow_dispatch:

env:
  NODE_OPTIONS: --max-old-space-size=4096

jobs:
  # ==========================================
  # JOB 1: Linting and Type Checking
  # ==========================================
  lint-and-typecheck:
    name: ğŸ” Lint & TypeCheck
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: Run TypeScript compiler check
        run: npx tsc --noEmit --skipLibCheck
      
      - name: Run ESLint (if configured)
        continue-on-error: true
        run: |
          if [ -f ".eslintrc.js" ] || [ -f ".eslintrc.json" ] || [ -f "eslint.config.js" ]; then
            npx eslint src/ tests/ --ext .ts --format=compact
          else
            echo "âš ï¸  No ESLint configuration found, skipping..."
          fi
      
      - name: Verify critical files exist
        run: |
          test -f package.json || exit 1
          test -f tsconfig.json || exit 1
          test -f main.ts || exit 1
          test -f manifest.json || exit 1
          echo "âœ… Critical files verified"

  # ==========================================
  # JOB 2: Unit Tests with Coverage
  # ==========================================
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        node-version: ['18.x', '20.x']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: Run unit tests with coverage
        run: npm run test:coverage
        env:
          NODE_ENV: test
      
      - name: Verify coverage thresholds
        run: |
          if [ -f "coverage/lcov.info" ]; then
            echo "âœ… Coverage report generated"
            # Show coverage summary
            if command -v lcov >/dev/null 2>&1; then
              lcov --summary coverage/lcov.info
            fi
          else
            echo "âš ï¸  No coverage report found"
          fi
      
      - name: Upload unit test coverage
        if: success()
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage/lcov.info
          flags: unit-tests
          name: unit-coverage-${{ matrix.os }}-node${{ matrix.node-version }}
          fail_ci_if_error: false
          verbose: true
      
      - name: Upload unit test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-${{ matrix.os }}-node${{ matrix.node-version }}
          path: |
            coverage/
            jest-results.xml
          retention-days: 30

  # ==========================================
  # JOB 3: E2E Node-based Tests
  # ==========================================
  e2e-node-tests:
    name: ğŸ”§ E2E Node Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        node-version: ['18.x', '20.x']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: Build plugin for E2E tests
        run: npm run build
      
      - name: Verify build outputs
        run: |
          test -f main.js || exit 1
          test -f manifest.json || exit 1
          echo "âœ… Build outputs verified for E2E tests"
      
      - name: Run E2E plugin loading tests
        id: plugin_loading
        run: |
          echo "ğŸš€ Running plugin loading tests..."
          npm run test:e2e 2>&1 | tee e2e-plugin-loading.log
          echo "exit_code=${PIPESTATUS[0]}" >> $GITHUB_OUTPUT
        continue-on-error: true
      
      - name: Run E2E SPARQL functionality tests  
        id: sparql_tests
        run: |
          echo "ğŸš€ Running SPARQL functionality tests..."
          npm run test:e2e:sparql 2>&1 | tee e2e-sparql.log
          echo "exit_code=${PIPESTATUS[0]}" >> $GITHUB_OUTPUT
        continue-on-error: true
      
      - name: Check E2E test results
        run: |
          plugin_exit=${{ steps.plugin_loading.outputs.exit_code }}
          sparql_exit=${{ steps.sparql_tests.outputs.exit_code }}
          
          echo "Plugin loading tests exit code: $plugin_exit"
          echo "SPARQL tests exit code: $sparql_exit"
          
          if [ "$plugin_exit" -ne "0" ] || [ "$sparql_exit" -ne "0" ]; then
            echo "âŒ One or more E2E tests failed"
            exit 1
          else
            echo "âœ… All E2E tests passed"
          fi
      
      - name: Upload E2E test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-logs-${{ matrix.os }}-node${{ matrix.node-version }}
          path: |
            e2e-*.log
            tests/e2e/
          retention-days: 30

  # ==========================================
  # JOB 4: UI Tests with Obsidian
  # ==========================================
  ui-tests:
    name: ğŸ–¥ï¸ UI Tests (Obsidian)
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        node-version: ['18.x', '20.x']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: Build plugin
        run: npm run build
      
      - name: Setup display server (Linux only)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update -q
          sudo apt-get install -y xvfb fluxbox x11-utils x11-xserver-utils
          # Start Xvfb
          export DISPLAY=:99
          Xvfb :99 -screen 0 1920x1080x24 -ac +extension GLX +render -noreset &
          # Wait for X server to start
          sleep 3
          # Start a lightweight window manager
          fluxbox -display :99 &
          sleep 2
          echo "DISPLAY=:99" >> $GITHUB_ENV
          
      - name: Download and setup Obsidian (Linux)
        if: runner.os == 'Linux'
        run: |
          OBSIDIAN_VERSION="1.6.7"
          curl -L -o Obsidian.AppImage "https://github.com/obsidianmd/obsidian-releases/releases/download/v${OBSIDIAN_VERSION}/Obsidian-${OBSIDIAN_VERSION}.AppImage"
          chmod +x Obsidian.AppImage
          echo "OBSIDIAN_APP_PATH=$PWD/Obsidian.AppImage" >> $GITHUB_ENV
          # Test that we can run Obsidian
          timeout 10s ./Obsidian.AppImage --version || echo "Obsidian version check completed"
      
      - name: Download and setup Obsidian (macOS)
        if: runner.os == 'macOS'
        run: |
          OBSIDIAN_VERSION="1.6.7"
          curl -L -o Obsidian.dmg "https://github.com/obsidianmd/obsidian-releases/releases/download/v${OBSIDIAN_VERSION}/Obsidian-${OBSIDIAN_VERSION}-universal.dmg"
          hdiutil attach Obsidian.dmg -nobrowse -noautoopen
          cp -R "/Volumes/Obsidian/Obsidian.app" .
          hdiutil detach "/Volumes/Obsidian" || true
          echo "OBSIDIAN_APP_PATH=$PWD/Obsidian.app" >> $GITHUB_ENV
      
      - name: Verify Obsidian installation
        run: |
          echo "Obsidian app path: $OBSIDIAN_APP_PATH"
          if [ -f "$OBSIDIAN_APP_PATH" ] || [ -d "$OBSIDIAN_APP_PATH" ]; then
            echo "âœ… Obsidian found at: $OBSIDIAN_APP_PATH"
          else
            echo "âŒ Obsidian not found at: $OBSIDIAN_APP_PATH"
            exit 1
          fi
      
      - name: Run UI tests with retry
        id: ui_tests
        run: |
          attempt=1
          max_attempts=3
          
          while [ $attempt -le $max_attempts ]; do
            echo "ğŸš€ UI Test attempt $attempt of $max_attempts"
            
            if npm run test:ui; then
              echo "âœ… UI tests passed on attempt $attempt"
              exit 0
            else
              echo "âŒ UI tests failed on attempt $attempt"
              if [ $attempt -eq $max_attempts ]; then
                echo "ğŸ’¥ All UI test attempts failed"
                exit 1
              fi
              
              echo "â³ Waiting 5 seconds before retry..."
              sleep 5
              attempt=$((attempt + 1))
            fi
          done
        env:
          DISPLAY: ${{ env.DISPLAY }}
          OBSIDIAN_APP_PATH: ${{ env.OBSIDIAN_APP_PATH }}
      
      - name: Upload UI test screenshots (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ui-test-screenshots-${{ matrix.os }}-node${{ matrix.node-version }}
          path: |
            wdio-logs/
            screenshots/
            errorShots/
          retention-days: 30
      
      - name: Upload UI test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ui-test-results-${{ matrix.os }}-node${{ matrix.node-version }}
          path: |
            wdio-logs/
            test-results/
            junit-results/
          retention-days: 30

  # ==========================================
  # JOB 5: Build Verification
  # ==========================================
  build-verification:
    name: ğŸ—ï¸ Build Verification
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: Clean previous build
        run: rm -f main.js main.js.map
      
      - name: Build plugin (development)
        run: npm run dev
      
      - name: Verify development build
        run: |
          test -f main.js || exit 1
          echo "âœ… Development build verified"
      
      - name: Clean and build for production
        run: |
          rm -f main.js main.js.map
          npm run build
      
      - name: Verify production build outputs
        run: |
          test -f main.js || exit 1
          test -f manifest.json || exit 1
          
          # Check file sizes
          MAIN_SIZE=$(wc -c < main.js)
          echo "main.js size: ${MAIN_SIZE} bytes"
          
          # Ensure main.js is not empty and reasonable size
          if [ "$MAIN_SIZE" -lt 1000 ]; then
            echo "âŒ main.js seems too small (${MAIN_SIZE} bytes)"
            exit 1
          fi
          
          # Verify manifest.json is valid JSON
          cat manifest.json | jq . > /dev/null
          
          echo "âœ… Production build verified"
      
      - name: Test plugin loading syntax
        run: |
          # Basic syntax check
          node -c main.js
          echo "âœ… Plugin JavaScript syntax is valid"
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            main.js
            manifest.json
            styles.css
          retention-days: 30

  # ==========================================
  # JOB 6: Test Results Summary
  # ==========================================
  test-summary:
    name: ğŸ“Š Test Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [lint-and-typecheck, unit-tests, e2e-node-tests, ui-tests, build-verification]
    timeout-minutes: 5
    
    steps:
      - name: Evaluate test results
        run: |
          echo "## ğŸ“‹ Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check results of each job
          lint_result="${{ needs.lint-and-typecheck.result }}"
          unit_result="${{ needs.unit-tests.result }}"
          e2e_result="${{ needs.e2e-node-tests.result }}"
          ui_result="${{ needs.ui-tests.result }}"
          build_result="${{ needs.build-verification.result }}"
          
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ” Lint & TypeCheck | $lint_result |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ§ª Unit Tests | $unit_result |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ”§ E2E Node Tests | $e2e_result |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ–¥ï¸ UI Tests | $ui_result |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ—ï¸ Build Verification | $build_result |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall status
          if [ "$lint_result" == "success" ] && [ "$unit_result" == "success" ] && [ "$e2e_result" == "success" ] && [ "$ui_result" == "success" ] && [ "$build_result" == "success" ]; then
            echo "âœ… **All tests passed successfully!**" >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "âŒ **Some tests failed. Check individual job logs for details.**" >> $GITHUB_STEP_SUMMARY
            
            # List failed jobs
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Failed Jobs:" >> $GITHUB_STEP_SUMMARY
            [ "$lint_result" != "success" ] && echo "- ğŸ” Lint & TypeCheck: $lint_result" >> $GITHUB_STEP_SUMMARY
            [ "$unit_result" != "success" ] && echo "- ğŸ§ª Unit Tests: $unit_result" >> $GITHUB_STEP_SUMMARY
            [ "$e2e_result" != "success" ] && echo "- ğŸ”§ E2E Node Tests: $e2e_result" >> $GITHUB_STEP_SUMMARY
            [ "$ui_result" != "success" ] && echo "- ğŸ–¥ï¸ UI Tests: $ui_result" >> $GITHUB_STEP_SUMMARY
            [ "$build_result" != "success" ] && echo "- ğŸ—ï¸ Build Verification: $build_result" >> $GITHUB_STEP_SUMMARY
            
            exit 1
          fi
      
      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const lint_result = "${{ needs.lint-and-typecheck.result }}";
            const unit_result = "${{ needs.unit-tests.result }}";
            const e2e_result = "${{ needs.e2e-node-tests.result }}";
            const ui_result = "${{ needs.ui-tests.result }}";
            const build_result = "${{ needs.build-verification.result }}";
            
            const allPassed = [lint_result, unit_result, e2e_result, ui_result, build_result].every(result => result === 'success');
            
            const body = `## ğŸ§ª Test Results
            
            | Test Suite | Status |
            |------------|--------|
            | ğŸ” Lint & TypeCheck | ${lint_result === 'success' ? 'âœ…' : 'âŒ'} ${lint_result} |
            | ğŸ§ª Unit Tests | ${unit_result === 'success' ? 'âœ…' : 'âŒ'} ${unit_result} |
            | ğŸ”§ E2E Node Tests | ${e2e_result === 'success' ? 'âœ…' : 'âŒ'} ${e2e_result} |
            | ğŸ–¥ï¸ UI Tests | ${ui_result === 'success' ? 'âœ…' : 'âŒ'} ${ui_result} |
            | ğŸ—ï¸ Build Verification | ${build_result === 'success' ? 'âœ…' : 'âŒ'} ${build_result} |
            
            ${allPassed ? 
              'âœ… **All tests passed! This PR is ready for review.**' : 
              'âŒ **Some tests failed. Please check the failed jobs and fix issues before merging.**'
            }
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });